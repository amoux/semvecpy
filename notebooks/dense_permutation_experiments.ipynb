{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with Dense Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from numba import jit\n",
    "sys.path.append(os.path.abspath('../')) # needed to import from permutations sibling directory\n",
    "import permutations.dense_permutations as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some vectors\n",
    "a = p.get_random_vector(100)\n",
    "b = p.get_random_vector(100)\n",
    "c = p.get_random_vector(100)\n",
    "\n",
    "# Generate some predicates\n",
    "p_a = p.get_random_permutation(100)\n",
    "p_b = p.get_random_permutation(100)\n",
    "p_c = p.get_random_permutation(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In theory, this should give us the ability to deduce a permutation from two source vectors; untested\n",
    "def deduceperm(permuted, unpermuted): \n",
    "     return np.argsort(np.argsort(permuted)[np.argsort(np.argsort(unpermuted))]) \n",
    "    \n",
    "\n",
    "# Changes a permutation to be like another permutation, where howmuch is the number of dimensions the input perm\n",
    "# should have in common with tobelike. In theory it should never become disjoint with range(dimension), but I haven't\n",
    "# rigorously tested it. Assuming it's fed with a permutation derived from range(dimension), that is.\n",
    "def trainpermutation(perm, tobelike, howmuch):\n",
    "    likeness = np.sum(perm == tobelike)\n",
    "    perm1 = np.copy(perm) \n",
    "    while likeness < howmuch: \n",
    "        tochange = np.random.choice(np.where(perm1 != tobelike)[0]) \n",
    "        perm1[np.where(perm1 == tobelike[tochange])] = perm1[tochange] \n",
    "        perm1[tochange] = tobelike[tochange] \n",
    "        likeness = np.sum(perm1 == tobelike) \n",
    "    return perm1        \n",
    "\n",
    "def trainpermutation(perm, tobelike, howmuch):\n",
    "    perm1 = np.copy(perm)\n",
    "    for i in np.where(perm1 == p.get_random_permutation(100))[0]: #move away from noise\n",
    "        idx = np.random.randint(0,perm1.shape[0])\n",
    "        val = perm1[i]\n",
    "        perm1[i] = perm[idx]\n",
    "        perm1[idx] = val\n",
    "    canchange = np.clip(howmuch, 0, len(np.where(perm1 != tobelike)[0])) # how many spaces can we actually change?\n",
    "    for i in np.argsort(np.abs(perm1 - tobelike))[::-1][:canchange]: # move towards the thing you want to be like\n",
    "        perm1[np.where(perm1 == tobelike[i])] = perm1[i] \n",
    "        perm1[i] = tobelike[i] \n",
    "    return perm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "p_ta = trainpermutation(p.get_random_permutation(100), p_a, 50) # make a permutation with 50 dimensions in common with p_a\n",
    "print(np.setdiff1d(np.arange(100), p_ta)) # should be an empty list\n",
    "print(np.sum(p_ta == p_a)) # should be precisely ~50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54481184\n",
      "0.81894934\n",
      "0.46748456\n",
      "0.46748456\n"
     ]
    }
   ],
   "source": [
    "print(p.cosine_similarity(a[p_a], a[p_b])) # basically random\n",
    "print(p.cosine_similarity(a[p_ta], a[p_a])) # same vector, more similar permutations, should be more similar\n",
    "print(p.cosine_similarity(a,b)) #should be identical to below permutation\n",
    "print(p.cosine_similarity(a[p_a], b[p_a])) # dissimilar vectors, same permutation, should be (identically to unpermuted) dissimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(deduceperm(a[p_a], a) == p_a) # should be 100 (e.g. every dimension should match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Things\n",
    "If we want to train, we should go for something like `sigmoid(vec[permutation].dot(vec2))`\n",
    "Ideally, we want the sigmoid to be very close to one for vectors in context, and far from one for negative samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(-np.logaddexp(0, -x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a toy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'orange': {\n",
    "        'isa': 'fruit',\n",
    "        'color': 'orange',\n",
    "        'colour': 'orange',\n",
    "        'shape': 'round',\n",
    "        'origin': 'plant',\n",
    "        'growson': 'tree'\n",
    "    },\n",
    "    'apple': {\n",
    "        'isa': 'fruit',\n",
    "        'colour':'red',\n",
    "        'color': 'red',\n",
    "        'shape': 'round',\n",
    "        'origin': 'plant',\n",
    "        'growson': 'tree'\n",
    "    },\n",
    "    'broccoli': {\n",
    "        'isa': 'vegetable',\n",
    "        'color': 'green',\n",
    "        'shape': 'floret',\n",
    "        'origin': 'plant',\n",
    "        'growson': 'bush'\n",
    "    },\n",
    "    'chicken': {\n",
    "        'isa': 'animal',\n",
    "        'makesnoise': 'cuccoo',\n",
    "        'has': 'feathers,',\n",
    "        'eats': 'grain',\n",
    "        'drinks': 'water'\n",
    "    },\n",
    "    'bicycle': {\n",
    "        'typeof':'transportation',\n",
    "        'origin':'man-made',\n",
    "        'color':'varies',\n",
    "        'has':'wheels',\n",
    "        'used-by':'humans'\n",
    "    }\n",
    "}\n",
    "\n",
    "svecs = {x:p.get_random_vector(100) for x in dataset.keys()} #generate subject vectors\n",
    "preds = {x:p.get_random_permutation(100) for y in dataset.keys() for x in dataset[y].keys()} # generate permutation vectors\n",
    "cvecs = {x:p.get_random_vector(100) for y in dataset.keys() for x in dataset[y].values()} # generate context vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "for i in range(100): # epochs\n",
    "    alpha = alpha - 0.001 # monotonic decrease in alpha\n",
    "    for subject in dataset.keys():\n",
    "        for predicate in dataset[subject]:\n",
    "            context = dataset[subject][predicate]\n",
    "            subjectvector = svecs[subject]\n",
    "            svectorcopy = svecs[subject].copy() # copy for context to move to\n",
    "            predicatevector = preds[predicate]\n",
    "            contextvector = cvecs[dataset[subject][predicate]]\n",
    "            cvectorcopy = cvecs[dataset[subject][predicate]].copy()\n",
    "            #print(f\"{subject}-{predicate}-{context} similarity prior to training: {p.cosine_similarity(p.permute_vector(predicatevector, subjectvector), contextvector):.2f}\")\n",
    "            shiftoward = 1-sigmoid(p.permute_vector(predicatevector, subjectvector).dot(contextvector))\n",
    "            shiftaway = -sigmoid(p.permute_vector(predicatevector, subjectvector).dot(p.get_random_vector(100))) # generate a random noise vector to move away from\n",
    "            subjectvector += alpha*shiftoward*contextvector[p.inverse_permutation(predicatevector)]\n",
    "            contextvector += alpha*shiftoward*p.permute_vector(predicatevector, svectorcopy)\n",
    "            subjectvector -= alpha*shiftaway*contextvector[p.inverse_permutation(predicatevector)]\n",
    "            contextvector -= alpha*shiftaway*p.permute_vector(predicatevector, svectorcopy)\n",
    "            #predicatevector = trainpermutation(predicatevector, deduceperm(cvectorcopy, svectorcopy), 5)\n",
    "            #print(f\"{subject}-{predicate}-{context} similarity after training: {p.cosine_similarity(p.permute_vector(predicatevector, subjectvector), contextvector):.2f}\")\n",
    "    #normalize vectors at end of every epoch\n",
    "    for vec in svecs:\n",
    "        svecs[vec] = p.normalize(svecs[vec])\n",
    "    for vec in cvecs:\n",
    "        cvecs[vec] = p.normalize(cvecs[vec])\n",
    "    #don't normalize predicate vectors as that would break things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_similarity_search(query, vectorstore):\n",
    "    similarities = [(i, p.cosine_similarity(vectorstore[i], vectorstore[query])) for i in vectorstore]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True) \n",
    "    for i in similarities[:5]:\n",
    "        print(f\"{i[0]+':':<10}\\t{i[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange:   \t1.0000\n",
      "apple:    \t0.9999\n",
      "broccoli: \t0.8592\n",
      "chicken:  \t0.5402\n",
      "bicycle:  \t0.4285\n"
     ]
    }
   ],
   "source": [
    "real_similarity_search('orange', svecs)\n",
    "#should be very similar to apples, a little similar to broccoli, and random to others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orange:   \t1.0000\n",
      "red:      \t0.9992\n",
      "green:    \t0.7463\n",
      "feathers,:\t0.5605\n",
      "plant:    \t0.5469\n"
     ]
    }
   ],
   "source": [
    "real_similarity_search('orange', cvecs)\n",
    "#should be similar to other colors, especially red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_similarity_search(query, permstore):\n",
    "    similarities = [(i, np.sum(permstore[query] == permstore[i])) for i in permstore]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i in similarities[:5]:\n",
    "        print(f\"{i[0]+':':<10}\\t{i[1]}\")\n",
    "              \n",
    "              \n",
    "#May want to do something like below\n",
    "'''def permutation_similarity_search(query, permstore):\n",
    "    comparevec = svecs['term that is probably related by query to svec']\n",
    "    similarities = [(i, p.cosine_similarity(comparevec[permstore[query]], comparevec[permstore[i]])) for i in permstore]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i in similarities[:5]:\n",
    "        print(f\"{i[0]+':':<10}\\t{i[1]:.4f}\")''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color:    \t100\n",
      "origin:   \t3\n",
      "colour:   \t1\n",
      "has:      \t1\n",
      "isa:      \t0\n"
     ]
    }
   ],
   "source": [
    "permutation_similarity_search('color', preds)\n",
    "#if preds aren't trained, should recover cue term and be random to other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_permutation_search(contextquery, subjectquery, contextstore, subjectstore, permstore):\n",
    "    similarities = [(i, np.sum(deduceperm(contextstore[contextquery], subjectstore[subjectquery]) == permstore[i])) for i in permstore]\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i in similarities[:5]:\n",
    "        print(f\"{i[0]+':':<10}\\t{i[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "color:    \t6\n",
      "colour:   \t3\n",
      "origin:   \t2\n",
      "used-by:  \t2\n",
      "isa:      \t1\n",
      "\n",
      "color:    \t6\n",
      "used-by:  \t4\n",
      "colour:   \t3\n",
      "isa:      \t1\n",
      "shape:    \t1\n"
     ]
    }
   ],
   "source": [
    "bound_permutation_search('orange','orange', cvecs, svecs, preds) # should return color\n",
    "print()\n",
    "bound_permutation_search('red','apple', cvecs, svecs, preds) # should return color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isa:      \t35\n",
      "color:    \t3\n",
      "origin:   \t2\n",
      "makesnoise:\t2\n",
      "drinks:   \t2\n"
     ]
    }
   ],
   "source": [
    "bound_permutation_search('fruit','orange', cvecs, svecs, preds) # should return isa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has:      \t65\n",
      "eats:     \t3\n",
      "typeof:   \t3\n",
      "colour:   \t2\n",
      "color:    \t1\n"
     ]
    }
   ],
   "source": [
    "bound_permutation_search('wheels','bicycle', cvecs, svecs, preds) # should return has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eats:     \t5\n",
      "colour:   \t2\n",
      "drinks:   \t2\n",
      "isa:      \t1\n",
      "color:    \t1\n"
     ]
    }
   ],
   "source": [
    "bound_permutation_search('fruit','bicycle', cvecs, svecs, preds)\n",
    "# should return random, especially without permutation training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train on a slightly larger toy data set derived from geonames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load countryfacts file (derived from geonames)\n",
    "# Note that some countries reported as NONE for capitals may actually have capitals, I just didn't resolve them\n",
    "# Antarctica has no capital and no official currency\n",
    "\n",
    "with open('../countryfacts.txt','r') as infile:\n",
    "    facts = [line.strip().split('\\t') for line in infile]\n",
    "\n",
    "facts = np.asarray(facts)\n",
    "\n",
    "subjects = set([x[0] for x in facts])\n",
    "predicates = set([x[1] for x in facts])\n",
    "objects = set([x[2] for x in facts])\n",
    "\n",
    "svecs = {x:p.get_random_vector(100) for x in subjects} #generate subject vectors\n",
    "preds = {x:p.get_random_permutation(100) for x in predicates} # generate permutation vectors\n",
    "cvecs = {x:p.get_random_vector(100) for x in objects} # generate context vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train based on how the attributes are related to each subject in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "for i in range(10): # epochs\n",
    "    # Shuffle the order of the examples:\n",
    "    np.random.shuffle(facts)\n",
    "    alpha = alpha - 0.001 # monotonic decrease in alpha\n",
    "    for fact in facts:\n",
    "        subjectvector = svecs[fact[0]]\n",
    "        svectorcopy = svecs[fact[0]].copy() # copy for context to move to\n",
    "        predicatevector = preds[fact[1]]\n",
    "        contextvector = cvecs[fact[2]]\n",
    "        cvectorcopy = cvecs[fact[2]].copy()\n",
    "        #print(f\"{subject}-{predicate}-{context} similarity prior to training: {p.cosine_similarity(p.permute_vector(predicatevector, subjectvector), contextvector):.2f}\")\n",
    "        shiftoward = 1-sigmoid(p.permute_vector(predicatevector, subjectvector).dot(contextvector))\n",
    "        shiftaway = -sigmoid(p.permute_vector(predicatevector, subjectvector).dot(p.get_random_vector(100))) # generate a random noise vector to move away from\n",
    "        subjectvector += alpha*shiftoward*contextvector[p.inverse_permutation(predicatevector)]\n",
    "        contextvector += alpha*shiftoward*p.permute_vector(predicatevector, svectorcopy)\n",
    "        subjectvector -= alpha*shiftaway*contextvector[p.inverse_permutation(predicatevector)]\n",
    "        contextvector -= alpha*shiftaway*p.permute_vector(predicatevector, svectorcopy)\n",
    "        #predicatevector = trainpermutation(predicatevector, deduceperm(contextvector, subjectvector), 75)\n",
    "        #print(f\"{subject}-{predicate}-{context} similarity after training: {p.cosine_similarity(p.permute_vector(predicatevector, subjectvector), contextvector):.2f}\")\n",
    "    #normalize vectors at end of every epoch\n",
    "    #for vec in svecs:\n",
    "    #    svecs[vec] = p.normalize(svecs[vec])\n",
    "    #for vec in cvecs:\n",
    "    #    cvecs[vec] = p.normalize(cvecs[vec])\n",
    "    #don't normalize predicate vectors as that would break things\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do some querying to make sure that it worked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States:\t1.0000\n",
      "Bermuda:  \t0.9957\n",
      "Turks and Caicos Islands:\t0.9957\n",
      "Bahamas:  \t0.9952\n",
      "Antigua and Barbuda:\t0.9950\n"
     ]
    }
   ],
   "source": [
    "real_similarity_search('United States', svecs) # should return other countries that are in NA and use \"Dollar\" as currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dollar:   \t1.0000\n",
      "Guilder:  \t0.7404\n",
      "Peso:     \t0.7363\n",
      "Vatu:     \t0.7209\n",
      "Cordoba:  \t0.6785\n"
     ]
    }
   ],
   "source": [
    "real_similarity_search('Dollar', cvecs) # should return other currencies used in NA / other currencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continent:\t100\n",
      "CurrencyName:\t0\n",
      "Capital:  \t0\n"
     ]
    }
   ],
   "source": [
    "permutation_similarity_search('Continent', preds) #preds aren't trained, so should recover cue term and be random to other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CurrencyName:\t9\n",
      "Continent:\t1\n",
      "Capital:  \t0\n",
      "\n",
      "CurrencyName:\t4\n",
      "Continent:\t1\n",
      "Capital:  \t0\n"
     ]
    }
   ],
   "source": [
    "bound_permutation_search('Dollar','United States', cvecs, svecs, preds) # should return currencyname\n",
    "print()\n",
    "bound_permutation_search('Peso','Mexico', cvecs, svecs, preds) # should return currencyname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capital:  \t2\n",
      "Continent:\t1\n",
      "CurrencyName:\t1\n",
      "\n",
      "Continent:\t2\n",
      "CurrencyName:\t1\n",
      "Capital:  \t1\n",
      "\n",
      "Continent:\t2\n",
      "CurrencyName:\t1\n",
      "Capital:  \t0\n",
      "\n",
      "Capital:  \t4\n",
      "Continent:\t3\n",
      "CurrencyName:\t0\n"
     ]
    }
   ],
   "source": [
    "bound_permutation_search('San Salvador','El Salvador', cvecs, svecs, preds) # should return Capital\n",
    "print()\n",
    "bound_permutation_search('Mexico City','Mexico', cvecs, svecs, preds)\n",
    "print()\n",
    "bound_permutation_search('Washington','United States', cvecs, svecs, preds)\n",
    "print()\n",
    "bound_permutation_search('London', 'United Kingdom', cvecs, svecs, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
